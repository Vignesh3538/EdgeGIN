{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaOLFT7f1EKp",
        "outputId": "a47883ce-3c7f-431b-8291-84af9b316ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (75.2.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.1.31)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install ogb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io1dxyCL1O5b",
        "outputId": "da52008e-2696-43fd-f148-3f2fbd22def4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.5.0 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fUz94Zn1Qwy",
        "outputId": "f0255c22-30ac-4023-c940-f6e122c40011"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.5.0\n",
            "  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting filelock (from torch==2.5.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.5.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.5.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.5.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.5.0)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.0)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.1\n",
            "    Uninstalling typing_extensions-4.13.1:\n",
            "      Successfully uninstalled typing_extensions-4.13.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.0 triton-3.1.0 typing-extensions-4.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ogb.linkproppred import LinkPropPredDataset, Evaluator\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn as nn\n",
        "from torch_geometric.utils import negative_sampling, scatter, add_self_loops, softmax\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "xL9hdItT1UEu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    dataset = LinkPropPredDataset(name=\"ogbl-ddi\")\n",
        "    split_edge = dataset.get_edge_split()\n",
        "    data = dataset[0]\n",
        "    return data, split_edge, dataset\n",
        "data, split_edge, dataset = load_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BeFBCKo1WSX",
        "outputId": "db00959a-9570-4f50-e3a9-e7efbc860143"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/linkproppred/ddi.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.04 GB: 100%|██████████| 46/46 [00:00<00:00, 67.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/ddi.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 33.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/ogb/linkproppred/dataset.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train = torch.load(osp.join(path, 'train.pt'))\n",
            "/usr/local/lib/python3.11/dist-packages/ogb/linkproppred/dataset.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  valid = torch.load(osp.join(path, 'valid.pt'))\n",
            "/usr/local/lib/python3.11/dist-packages/ogb/linkproppred/dataset.py:140: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test = torch.load(osp.join(path, 'test.pt'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = torch.from_numpy(split_edge['train']['edge']).long().T.contiguous()\n",
        "num_nodes = 4267\n",
        "print(f\"Edge Index Shape: {edge_index.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLKPG2LG1XYQ",
        "outputId": "fd38d161-3fe5-4929-a78c-8df0db06ab8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index Shape: torch.Size([2, 1067911])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_edge_features(edge_index, chunk_size=1000):\n",
        "    device = edge_index.device\n",
        "    row, col = edge_index\n",
        "    edge_index = torch.cat([edge_index, torch.stack([col, row])], dim=1)\n",
        "\n",
        "    adj = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.size(1), device=device),\n",
        "                                  (num_nodes, num_nodes), device=device)\n",
        "    degrees = torch.sparse.sum(adj, dim=1).to_dense()\n",
        "\n",
        "    src, dst = torch.triu_indices(num_nodes, num_nodes, offset=1, device=device)\n",
        "    num_pairs = src.size(0)\n",
        "\n",
        "    feat_list = []\n",
        "    pair_list = []\n",
        "\n",
        "    for i in range(0, num_pairs, chunk_size):\n",
        "        s = src[i:i+chunk_size]\n",
        "        d = dst[i:i+chunk_size]\n",
        "\n",
        "        adj_s = torch.index_select(adj.to_dense(), 0, s)\n",
        "        adj_d = torch.index_select(adj.to_dense(), 0, d)\n",
        "\n",
        "        inter = adj_s * adj_d\n",
        "        union = ((adj_s + adj_d) > 0).float()\n",
        "\n",
        "        cn = inter.sum(dim=1)\n",
        "        jc = cn / union.sum(dim=1).clamp(min=1)\n",
        "        aa = (inter / torch.log(degrees + 1e-10)[None, :]).nan_to_num(0).sum(dim=1)\n",
        "        pa = degrees[s] * degrees[d]\n",
        "        ra = (inter / degrees[None, :].clamp(min=1)).nan_to_num(0).sum(dim=1)\n",
        "        si = 2 * cn / (degrees[s] + degrees[d]).clamp(min=1)\n",
        "        hpi = cn / torch.min(degrees[s], degrees[d]).clamp(min=1)\n",
        "        hdi = cn / torch.max(degrees[s], degrees[d]).clamp(min=1)\n",
        "\n",
        "        feats = torch.stack([cn, jc, aa, pa, ra, si, hpi, hdi], dim=1)\n",
        "        feat_list.append(feats)\n",
        "        pair_list.append(torch.stack([s, d], dim=1))\n",
        "\n",
        "        del adj_s, adj_d, inter, union, feats\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    all_pairs = torch.cat(pair_list, dim=0)  # [E, 2]\n",
        "    all_feats = torch.cat(feat_list, dim=0)  # [E, 8]\n",
        "\n",
        "    return all_feats, all_pairs"
      ],
      "metadata": {
        "id": "xj5I5pzy1fOb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_all_feats_matrix(all_pairs, all_feats):\n",
        "    u = torch.minimum(all_pairs[:, 0], all_pairs[:, 1])\n",
        "    v = torch.maximum(all_pairs[:, 0], all_pairs[:, 1])\n",
        "\n",
        "    all_feats_matrix = torch.zeros((num_nodes, num_nodes, all_feats.size(1)),\n",
        "                                   dtype=all_feats.dtype,\n",
        "                                   device=all_feats.device)\n",
        "    all_feats_matrix[u, v] = all_feats  # Store in upper triangle\n",
        "\n",
        "    return all_feats_matrix\n"
      ],
      "metadata": {
        "id": "H0h3oN5N1jCn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "edge_index=edge_index.to(device)\n",
        "edge_feats, all_pairs = compute_edge_features(edge_index)\n"
      ],
      "metadata": {
        "id": "jlJt_Ioi1pKH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = edge_feats.mean(dim=0, keepdim=True)\n",
        "stds = edge_feats.std(dim=0, keepdim=True)\n",
        "edge_feats[:, 0] = torch.log1p(edge_feats[:, 0])  # cn\n",
        "edge_feats[:, 2] = torch.log1p(edge_feats[:, 2])  # aa\n",
        "edge_feats[:, 3] = torch.log1p(edge_feats[:, 3])  # pa\n",
        "edge_feats[:, 4] = torch.log1p(edge_feats[:, 4])  # ra\n",
        "\n",
        "edge_feats = (edge_feats - means) / (stds + 1e-10)\n",
        "edge_features = build_all_feats_matrix(all_pairs, edge_feats)"
      ],
      "metadata": {
        "id": "aP0bqFUK1qir"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_undirected_negative_sampling(edge_index, num_nodes, num_samples):\n",
        "    u, v = edge_index\n",
        "    pos_u = torch.min(u, v)\n",
        "    pos_v = torch.max(u, v)\n",
        "    pos_pairs = pos_u * num_nodes + pos_v  # unique undirected ID\n",
        "    pos_set = pos_pairs.unique()\n",
        "\n",
        "    neg_set = set()\n",
        "    max_trials = num_samples * 10\n",
        "    trials = 0\n",
        "\n",
        "    while len(neg_set) < num_samples and trials < max_trials:\n",
        "        i = torch.randint(0, num_nodes, (num_samples * 2,))\n",
        "        j = torch.randint(0, num_nodes, (num_samples * 2,))\n",
        "        mask = i != j\n",
        "        i, j = i[mask], j[mask]\n",
        "\n",
        "        u = torch.min(i, j)\n",
        "        v = torch.max(i, j)\n",
        "        pair_ids = u * num_nodes + v\n",
        "\n",
        "        valid_mask = ~torch.isin(pair_ids, pos_set)\n",
        "        u, v, pair_ids = u[valid_mask], v[valid_mask], pair_ids[valid_mask]\n",
        "\n",
        "        for a, b, pid in zip(u.tolist(), v.tolist(), pair_ids.tolist()):\n",
        "            if pid not in neg_set:\n",
        "                neg_set.add(pid)\n",
        "                if len(neg_set) == num_samples:\n",
        "                    break\n",
        "        trials += 1\n",
        "\n",
        "    neg_pairs = torch.tensor([(pid // num_nodes, pid % num_nodes) for pid in neg_set], dtype=torch.long).t()\n",
        "    neg_sym = torch.cat([neg_pairs, neg_pairs[[1, 0]]], dim=1)  # add reverse edges\n",
        "    return neg_sym\n",
        "\n"
      ],
      "metadata": {
        "id": "oDztBxw21vCC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_edges = edge_index.shape[1]\n",
        "\n",
        "perm = torch.randperm(num_edges)\n",
        "shuffled_edges = edge_index[:, perm]\n",
        "\n",
        "split_idx = int(0.8 * num_edges)\n",
        "message_passing_edges = shuffled_edges[:, :split_idx]\n",
        "train_supervision_edges = shuffled_edges[:, split_idx:]\n",
        "\n",
        "def add_reverse_edges(edges):\n",
        "    return torch.cat([edges, edges[[1, 0]]], dim=1)\n",
        "\n",
        "message_passing_edges = add_reverse_edges(message_passing_edges)\n",
        "train_supervision_edges = add_reverse_edges(train_supervision_edges)\n",
        "\n",
        "print(f\"Message Passing Edges Shape: {message_passing_edges.shape}\")\n",
        "print(f\"Train Supervision Edges Shape: {train_supervision_edges.shape}\")\n",
        "\n",
        "num_neg_samples = train_supervision_edges.shape[1] // 2\n",
        "neg_edge_index = fast_undirected_negative_sampling(edge_index.to('cpu'), num_nodes, num_neg_samples)\n",
        "print(f\"Negative Edge Index Shape: {neg_edge_index.shape}\")\n"
      ],
      "metadata": {
        "id": "VWSgWPbB1yZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce442825-d15d-4449-9620-bef9529b6ec1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message Passing Edges Shape: torch.Size([2, 1708656])\n",
            "Train Supervision Edges Shape: torch.Size([2, 427166])\n",
            "Negative Edge Index Shape: torch.Size([2, 427166])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GINLayer(MessagePassing):\n",
        "    def __init__(self, in_dim, hidden_dim, eps=0):\n",
        "        super().__init__(aggr=\"sum\")\n",
        "\n",
        "        self.mlp_phi = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.eps = nn.Parameter(torch.Tensor([eps]))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = x.to(self.mlp_phi[0].weight.device)\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        return self.propagate(edge_index, x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return (x_j)\n",
        "\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        out = (1 + self.eps) * (x) + aggr_out\n",
        "        return self.mlp_phi(out)\n",
        "\n",
        "\n",
        "class GINLinkPredictor(nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.node_emb = nn.Embedding(num_nodes, hidden_dim)\n",
        "        init.xavier_uniform_(self.node_emb.weight)\n",
        "        self.gin1 = GINLayer(hidden_dim, hidden_dim)\n",
        "        self.gin2 = GINLayer(hidden_dim, hidden_dim)\n",
        "        self.gin3 = GINLayer(hidden_dim, hidden_dim)\n",
        "        self.edge_predictor1 = nn.Sequential(\n",
        "                nn.Linear(2 * hidden_dim, 100),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.Linear(100, 60),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(60, 30),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(30, 1)\n",
        "                )\n",
        "        self.edge_predictor2 = nn.Sequential(\n",
        "                nn.Linear(8, 32),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(32, 1)\n",
        "\n",
        "                )\n",
        "\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        x = self.node_emb.weight.to(edge_index.device)\n",
        "\n",
        "        x = self.gin1(x, edge_index)\n",
        "        x = self.gin2(x, edge_index)\n",
        "        x = self.gin3(x, edge_index)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def predict_edges(self, x, edge_index, alpha = 0.001):\n",
        "        src, dst = edge_index\n",
        "\n",
        "        edge_feats = edge_features[torch.min(src, dst), torch.max(src, dst)]\n",
        "\n",
        "        node_embeddings = torch.cat([x[src], x[dst]], dim=1)\n",
        "\n",
        "        return self.edge_predictor1(node_embeddings).squeeze(-1) +  alpha * self.edge_predictor2(edge_feats).squeeze(-1)\n",
        "\n",
        "@torch.compile\n",
        "def train_step(model, optimizer, scheduler, edge_index, train_edges, neg_edges, val_edges, val_neg_edges, device):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x = model(edge_index.to(device))\n",
        "\n",
        "    pos = model.predict_edges(x, train_edges)\n",
        "    neg = model.predict_edges(x, neg_edges)\n",
        "\n",
        "    scores = torch.cat([pos, neg], dim=0)\n",
        "    labels = torch.cat([\n",
        "        torch.ones_like(pos),\n",
        "        torch.zeros_like(neg)\n",
        "    ], dim=0)\n",
        "\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "    loss = bce_loss_fn(scores, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = model(edge_index.to(device))\n",
        "        pos_val = model.predict_edges(x, val_edges.to(device))\n",
        "        neg_val = model.predict_edges(x, val_neg_edges.to(device))\n",
        "        input_dict = {\"y_pred_pos\": pos_val.view(-1), \"y_pred_neg\": neg_val.view(-1)}\n",
        "        result = run_eval(input_dict)\n",
        "    return loss, result[\"hits@20\"]"
      ],
      "metadata": {
        "id": "NHurNYWf1_MM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_step(model, edge_index, test_pos_edges, test_neg_edges, evaluator, device):\n",
        "    model.eval()\n",
        "    x = model(edge_index.to(device))\n",
        "\n",
        "    pos_preds = model.predict_edges(x, test_pos_edges.to(device))\n",
        "    neg_preds = model.predict_edges(x, test_neg_edges.to(device))\n",
        "\n",
        "    avg_pos_score = pos_preds.mean().item()\n",
        "    avg_neg_score = neg_preds.mean().item()\n",
        "    top20_neg_avg = torch.topk(neg_preds, 20, largest=True).values.mean().item()\n",
        "\n",
        "    print(f\"🔹 Avg Positive Edge Score: {avg_pos_score:.15f}\")\n",
        "    print(f\"🔻 Avg Negative Edge Score: {avg_neg_score:.15f}\")\n",
        "    print(f\"🔺 Avg Top 20 Negative Edge Score: {top20_neg_avg:.15f}\")\n",
        "\n",
        "    input_dict = {\"y_pred_pos\": pos_preds.view(-1), \"y_pred_neg\": neg_preds.view(-1)}\n",
        "    result = evaluator.eval(input_dict)\n",
        "\n",
        "    pos_labels = torch.ones_like(pos_preds)\n",
        "    neg_labels = torch.zeros_like(neg_preds)\n",
        "\n",
        "    y_true = torch.cat([pos_labels, neg_labels], dim=0)\n",
        "    y_pred = torch.cat([pos_preds, neg_preds], dim=0)\n",
        "    y_pred = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "\n",
        "    correct = (y_pred == y_true).sum().item()\n",
        "    accuracy = correct / y_true.numel()\n",
        "\n",
        "    true_positives = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
        "    predicted_positives = (y_pred == 1).sum().item()\n",
        "    actual_positives = (y_true == 1).sum().item()\n",
        "\n",
        "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0.0\n",
        "    recall = true_positives / actual_positives if actual_positives > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"🎯 Precision: {precision:.4f}\")\n",
        "    print(f\"🔄 Recall: {recall:.4f}\")\n",
        "    print(f\"⭐ F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return result[\"hits@20\"]\n"
      ],
      "metadata": {
        "id": "LoLEM9Ny2y4p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator(name=\"ogbl-ddi\")"
      ],
      "metadata": {
        "id": "ctyFvdwJ23VL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch._dynamo.disable\n",
        "def run_eval(input_dict):\n",
        "    return evaluator.eval(input_dict)"
      ],
      "metadata": {
        "id": "PjBD4eH224Lk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_edges = torch.tensor(split_edge['valid']['edge'].T, dtype=torch.long, device=device)\n",
        "val_neg_edges = torch.tensor(split_edge['valid']['edge_neg'].T, dtype=torch.long, device=device)"
      ],
      "metadata": {
        "id": "Bt9TZJDO3Ap5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = \"path_to_model\""
      ],
      "metadata": {
        "id": "HOCqzZxDUIuI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GINLinkPredictor(num_nodes=4267, hidden_dim=256).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
        "model.compile()\n",
        "print(f\"Using device: {device}\")\n",
        "best = 0.0\n",
        "num_epochs=1500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss, val_hits_at_20 = train_step(model, optimizer, scheduler, message_passing_edges, train_supervision_edges, neg_edge_index,val_edges, val_neg_edges, device)\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {loss:.15f}, Val hits at 20: {val_hits_at_20:.15f}\")\n",
        "\n",
        "    if val_hits_at_20 > best:\n",
        "        best = val_hits_at_20\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"Model saved at epoch {epoch+1} with loss {loss:.15f}\")\n"
      ],
      "metadata": {
        "id": "QKP-l80s2-hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(save_path, num_nodes, device):\n",
        "    model = GINLinkPredictor(num_nodes=num_nodes, hidden_dim=256).to(device)\n",
        "    model.load_state_dict(torch.load(save_path, map_location=device, weights_only = False))\n",
        "    model.eval()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fRoNupq13N4e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(SAVE_PATH, num_nodes=4267, device=device)"
      ],
      "metadata": {
        "id": "tWGWKpnX3OoN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "message_passing_edges = torch.load(\"path_to_message_passing_edges\",weights_only = False).to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kqnDONcVV1wW",
        "outputId": "3a67522b-afa1-4312-9049-2985f006e913"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fb4ed85-bd1f-4d44-b755-3859f2c2615b\", \"message_passing_edges_eh.pt\", 27339825)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hits_at_20 = test_step(loaded_model, message_passing_edges, val_edges, val_neg_edges, evaluator, device)\n",
        "print(f\"Test Hits@20 (OGB Evaluator): {hits_at_20:.15f}\")"
      ],
      "metadata": {
        "id": "li1GzJO03TwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d82ca7-db76-4a95-8b67-3ae68a9ba495"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Avg Positive Edge Score: 2.816118478775024\n",
            "🔻 Avg Negative Edge Score: -5.789036750793457\n",
            "🔺 Avg Top 20 Negative Edge Score: 3.613739728927612\n",
            "✅ Accuracy: 0.9507\n",
            "🎯 Precision: 0.9536\n",
            "🔄 Recall: 0.9598\n",
            "⭐ F1 Score: 0.9567\n",
            "Test Hits@20 (OGB Evaluator): 0.372113058004779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos_edges = torch.tensor(split_edge['test']['edge'].T, dtype=torch.long, device=device)\n",
        "test_neg_edges = torch.tensor(split_edge['test']['edge_neg'].T, dtype=torch.long, device=device)\n",
        "\n",
        "hits_at_20 = test_step(loaded_model, message_passing_edges, test_pos_edges, test_neg_edges, evaluator, device)\n",
        "print(f\"Test Hits@20 (OGB Evaluator): {hits_at_20:.15f}\")"
      ],
      "metadata": {
        "id": "7XWIBD-m3bMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cb37d4-122a-4112-dc12-072534954e0a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Avg Positive Edge Score: 2.205512762069702\n",
            "🔻 Avg Negative Edge Score: -5.649230003356934\n",
            "🔺 Avg Top 20 Negative Edge Score: 2.930077075958252\n",
            "✅ Accuracy: 0.9461\n",
            "🎯 Precision: 0.9649\n",
            "🔄 Recall: 0.9417\n",
            "⭐ F1 Score: 0.9532\n",
            "Test Hits@20 (OGB Evaluator): 0.392519233794545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_params(model):\n",
        "    print(\"Trainable Parameters:\")\n",
        "    total_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"{name}: {param.shape} | {param.numel()} params\")\n",
        "            total_params += param.numel()\n",
        "\n",
        "    print(f\"Total Trainable Parameters: {total_params}\")\n",
        "\n",
        "print_trainable_params(loaded_model)\n"
      ],
      "metadata": {
        "id": "2FLs8Q5k3dOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8b5f21-7218-4741-edb7-77e04ec25985"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Parameters:\n",
            "node_emb.weight: torch.Size([4267, 256]) | 1092352 params\n",
            "gin1.eps: torch.Size([1]) | 1 params\n",
            "gin1.mlp_phi.0.weight: torch.Size([256, 256]) | 65536 params\n",
            "gin1.mlp_phi.0.bias: torch.Size([256]) | 256 params\n",
            "gin1.mlp_phi.1.weight: torch.Size([256]) | 256 params\n",
            "gin1.mlp_phi.1.bias: torch.Size([256]) | 256 params\n",
            "gin1.mlp_phi.4.weight: torch.Size([256, 256]) | 65536 params\n",
            "gin1.mlp_phi.4.bias: torch.Size([256]) | 256 params\n",
            "gin1.mlp_phi.5.weight: torch.Size([256]) | 256 params\n",
            "gin1.mlp_phi.5.bias: torch.Size([256]) | 256 params\n",
            "gin2.eps: torch.Size([1]) | 1 params\n",
            "gin2.mlp_phi.0.weight: torch.Size([256, 256]) | 65536 params\n",
            "gin2.mlp_phi.0.bias: torch.Size([256]) | 256 params\n",
            "gin2.mlp_phi.1.weight: torch.Size([256]) | 256 params\n",
            "gin2.mlp_phi.1.bias: torch.Size([256]) | 256 params\n",
            "gin2.mlp_phi.4.weight: torch.Size([256, 256]) | 65536 params\n",
            "gin2.mlp_phi.4.bias: torch.Size([256]) | 256 params\n",
            "gin2.mlp_phi.5.weight: torch.Size([256]) | 256 params\n",
            "gin2.mlp_phi.5.bias: torch.Size([256]) | 256 params\n",
            "gin3.eps: torch.Size([1]) | 1 params\n",
            "gin3.mlp_phi.0.weight: torch.Size([256, 256]) | 65536 params\n",
            "gin3.mlp_phi.0.bias: torch.Size([256]) | 256 params\n",
            "gin3.mlp_phi.1.weight: torch.Size([256]) | 256 params\n",
            "gin3.mlp_phi.1.bias: torch.Size([256]) | 256 params\n",
            "gin3.mlp_phi.4.weight: torch.Size([256, 256]) | 65536 params\n",
            "gin3.mlp_phi.4.bias: torch.Size([256]) | 256 params\n",
            "gin3.mlp_phi.5.weight: torch.Size([256]) | 256 params\n",
            "gin3.mlp_phi.5.bias: torch.Size([256]) | 256 params\n",
            "edge_predictor1.0.weight: torch.Size([100, 512]) | 51200 params\n",
            "edge_predictor1.0.bias: torch.Size([100]) | 100 params\n",
            "edge_predictor1.3.weight: torch.Size([60, 100]) | 6000 params\n",
            "edge_predictor1.3.bias: torch.Size([60]) | 60 params\n",
            "edge_predictor1.5.weight: torch.Size([30, 60]) | 1800 params\n",
            "edge_predictor1.5.bias: torch.Size([30]) | 30 params\n",
            "edge_predictor1.7.weight: torch.Size([1, 30]) | 30 params\n",
            "edge_predictor1.7.bias: torch.Size([1]) | 1 params\n",
            "edge_predictor2.0.weight: torch.Size([32, 8]) | 256 params\n",
            "edge_predictor2.0.bias: torch.Size([32]) | 32 params\n",
            "edge_predictor2.2.weight: torch.Size([1, 32]) | 32 params\n",
            "edge_predictor2.2.bias: torch.Size([1]) | 1 params\n",
            "Total Trainable Parameters: 1549721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUdE_c89-5zE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}